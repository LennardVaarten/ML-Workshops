{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CLASS_breast_cancer.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Q64WwNNUo2LL"},"outputs":[],"source":["# importing libraries, etc...\n","\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","sns.set()\n","\n","path = \"https://raw.githubusercontent.com/LennardVaarten/ML-Workshops/main/data/\""]},{"cell_type":"markdown","source":["Breast cancer is cancer that uncontrollably grows breast cells. The grown cells form a tumor can be malignant (dangerous) or benign (not malignant). Breast cancer diagnosis is to determine whether a tumor is malignant or not.\n","\n","Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe the characteristics of the cell nuclei present in the image."],"metadata":{"id":"HQRYnzX39hFD"}},{"cell_type":"markdown","source":["# **Loading And Viewing The Data**"],"metadata":{"id":"wCC0NcUv0_91"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"402854d8"},"outputs":[],"source":["# loading the dataset\n","\n","bc = pd.read_csv(path+\"breast_cancer.csv\")"]},{"cell_type":"code","source":["# viewing\n","\n","bc"],"metadata":{"id":"jSBxfpl7IOHN"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c64db562"},"outputs":[],"source":["# how often does each target label appear?\n","\n","bc[\"diagnosis_M\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"a59e09de"},"outputs":[],"source":["# scaling the features, so that each feature ranges from 0 to 1\n","\n","from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler().fit(bc.iloc[:,1:])\n","\n","bc.iloc[:,1:] = scaler.transform(bc.iloc[:,1:])"]},{"cell_type":"code","source":["bc"],"metadata":{"id":"8l7PWxOxJDTB"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a0e73858"},"outputs":[],"source":["# splitting the data into a training set and test set\n","\n","from sklearn.model_selection import train_test_split\n","\n","features_train, features_test, target_train, target_test = train_test_split(bc.iloc[:,1:], \n","                                                                            bc.iloc[:,0], \n","                                                                            random_state=99)"]},{"cell_type":"markdown","metadata":{"id":"248cc5f0"},"source":["# **Overfitting and Underfitting**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f02a8093"},"outputs":[],"source":["# training k-NN with different values of k to show overfitting and underfitting\n","\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","neighbors = []\n","training_accuracy = []\n","test_accuracy = []\n","neighbors_settings = [n for n in range(1,41,2)]\n","\n","for k in neighbors_settings:\n","    knn = KNeighborsClassifier(n_neighbors=k).fit(features_train, target_train)\n","    neighbors.append(k)\n","    training_accuracy.append(knn.score(features_train, target_train))\n","    test_accuracy.append(knn.score(features_test, target_test))\n","\n","results = pd.DataFrame([neighbors, training_accuracy, test_accuracy]).T\n","results.columns = [\"k\", \"training accuracy\", \"test accuracy\"]\n","results = pd.melt(results, \n","                  id_vars='k', \n","                  var_name=\"train_test\", \n","                  value_name=\"score\")\n","\n","sns.lineplot(x='k', \n","             y='score', \n","             hue='train_test', \n","             data=results)"]},{"cell_type":"markdown","source":["# **Decision Tree Classifier**"],"metadata":{"id":"RgE71wHIv7nP"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ced089b0"},"outputs":[],"source":["# training the decision tree classifier\n","\n","from sklearn.tree import DecisionTreeClassifier\n","\n","tree = DecisionTreeClassifier(random_state=99).fit(features_train, target_train)\n","print(\"Accuracy on training set: {:.3f}\".format(tree.score(features_train, target_train)))\n","print(\"Accuracy on test set: {:.3f}\".format(tree.score(features_test, target_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ffb5785f"},"outputs":[],"source":["# how does our decision tree classifier come to a decision?\n","\n","from sklearn.tree import plot_tree\n","\n","fn = list(bc.columns)\n","cn = [\"B\", \"M\"]\n","fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(17,17), dpi=150)\n","plot_tree(tree, feature_names=fn, class_names=cn, filled=True, fontsize=6);"]},{"cell_type":"markdown","source":["## Pruning with max_depth"],"metadata":{"id":"1DJeUQcQzDLh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"96f7b661"},"outputs":[],"source":["# pruning by limiting the maximum depth of the decision tree\n","\n","tree = DecisionTreeClassifier(max_depth=3, random_state=99).fit(features_train, target_train)\n","print(\"Accuracy on training set: {:.3f}\".format(tree.score(features_train, target_train)))\n","print(\"Accuracy on test set: {:.3f}\".format(tree.score(features_test, target_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"76164e96"},"outputs":[],"source":["# plotting our pruned decision tree\n","\n","fn = list(bc.columns)\n","cn = [\"B\", \"M\"]\n","fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(7,7), dpi=150)\n","plot_tree(tree, feature_names=fn, class_names=cn, filled=True, fontsize=6);"]},{"cell_type":"markdown","source":["## Pruning with min_samples_split"],"metadata":{"id":"wOjhAgHFzLny"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cc2bbb7f"},"outputs":[],"source":["# another way of pruning is by only allowing a split to be made\n","\n","tree = DecisionTreeClassifier(max_depth=6, min_samples_split=5, max_leaf_nodes=10, random_state=99).fit(features_train, target_train)\n","print(\"Accuracy on training set: {:.3f}\".format(tree.score(features_train, target_train)))\n","print(\"Accuracy on test set: {:.3f}\".format(tree.score(features_test, target_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ef050b6c"},"outputs":[],"source":["fn = list(bc.columns)\n","cn = [\"B\", \"M\"]\n","fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(15,15), dpi=100)\n","plot_tree(tree, feature_names=fn, class_names=cn, filled=True, fontsize=6);"]},{"cell_type":"markdown","source":["## Feature Importances"],"metadata":{"id":"2Lq73s5EzRs3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dc00a98f"},"outputs":[],"source":["fn = bc.columns[1:]\n","fi = tree.feature_importances_[1:]\n","fn_sorted = [x for _, x in sorted(zip(fi,fn), reverse=True)]\n","fi_sorted = sorted(fi, reverse=True)\n","\n","for fn, fi in zip(fn_sorted, fi_sorted):\n","    print(f\"{fn:25} {fi:.3f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6f0685f9"},"outputs":[],"source":["print(sum(tree.feature_importances_))"]},{"cell_type":"markdown","metadata":{"id":"1f4a4faa"},"source":["# **Random Forest Classifier**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4fb82ee9"},"outputs":[],"source":["# training the random forest classifier\n","\n","from sklearn.ensemble import RandomForestClassifier\n","\n","rf = RandomForestClassifier(n_estimators=1000, max_depth=4, random_state=99)\n","rf.fit(features_train, target_train)\n","\n","print(\"Accuracy on training set: {:.3f}\".format(rf.score(features_train, target_train)))\n","print(\"Accuracy on test set: {:.3f}\".format(rf.score(features_test, target_test)))"]},{"cell_type":"markdown","source":["## Feature Importances"],"metadata":{"id":"uo3SK_msx079"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3cdd6795"},"outputs":[],"source":["# looking at feature importances of random forest classifier\n","\n","fn_sorted = [fn for fi, fn in sorted(zip(rf.feature_importances_, list(bc.columns)[1:]), reverse=True)]\n","fi_sorted = sorted(list(rf.feature_importances_), reverse=True)\n","\n","for fn, fi in zip(fn_sorted, fi_sorted):\n","    print(f\"{fn:25} {fi:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"33df874b"},"source":["# **Gradient Boosting Classifier**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"772bb10c"},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","gbc = GradientBoostingClassifier(n_estimators=1000, max_depth=3, subsample=0.4, learning_rate=0.1, random_state=99)\n","gbc.fit(features_train, target_train)\n","\n","print(\"Accuracy on training set: {:.3f}\".format(gbc.score(features_train, target_train)))\n","print(\"Accuracy on test set: {:.3f}\".format(gbc.score(features_test, target_test)))"]},{"cell_type":"markdown","source":["# **Cross-Validation**"],"metadata":{"id":"GMcMSXsHXtmk"}},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_score\n","from sklearn.ensemble import RandomForestClassifier\n","\n","rf = RandomForestClassifier(n_estimators=500, random_state=99)\n","rf.fit(features_train, target_train)\n","\n","rfScores = cross_val_score(rf, features_train, target_train, cv=10)\n","print(rfScores)\n","print(f\"Random Forest mean 5-fold Cross-Validation score: {np.mean(rfScores):.3f}\")"],"metadata":{"id":"VL1xpIi8aHKP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["knn = KNeighborsClassifier(n_neighbors=5).fit(features_train, target_train)\n","gbc.fit(features_train, target_train)\n","\n","knnScores = cross_val_score(knn, features_train, target_train, cv=10)\n","print(knnScores)\n","print(f\"k-NN mean 5-fold Cross-Validation score: {np.mean(knnScores):.3f}\")"],"metadata":{"id":"0BAj-JicWjOb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Leave-One-Out Cross-Validation"],"metadata":{"id":"9awYGZ-yAe7c"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"e1615077"},"outputs":[],"source":["from sklearn.model_selection import LeaveOneOut\n","\n","knn = KNeighborsClassifier(n_neighbors=5)\n","knnScores = cross_val_score(knn, features_train, target_train, cv=LeaveOneOut())\n","\n","print(f\"k-NN mean Leave-One-Out Cross-Validation score: {np.mean(knnScores):.3f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"e0dfb8e2"},"outputs":[],"source":["print(f\"Total models trained: {len(knnScores)}\")\n","print(\"Score for each model:\")\n","print(knnScores)"]},{"cell_type":"markdown","metadata":{"id":"f87b92ca"},"source":["# **Grid Search**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5aff582"},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","\n","params = {\n","    \"n_neighbors\": [k for k in range(1, 21, 2)],\n","    \"weights\": [\"uniform\", \"distance\"]\n","}\n","\n","knn = GridSearchCV(estimator=KNeighborsClassifier(),\n","                   param_grid=params) \n","\n","knn.fit(features_train, target_train)\n","\n","print(\"Best CV score on training set: {:.3f}\".format(knn.best_score_))\n","print(\"Score on test set: {:.3f}\".format(knn.score(features_test, target_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"41ba5ccb"},"outputs":[],"source":["# Check out which model parameters performed best\n","\n","knn.best_params_"]},{"cell_type":"markdown","source":["# **Evaluation Metrics**"],"metadata":{"id":"AwtiSEg_QHYu"}},{"cell_type":"markdown","source":["## Confusion Matrix"],"metadata":{"id":"XL3dq3l-Hq-w"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"01289e1b"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","\n","logreg = LogisticRegression(C=10, random_state=99)\n","logreg.fit(features_train, target_train)\n","\n","print(\"Accuracy on training set: {:.4f}\".format(logreg.score(features_train, target_train)))\n","print(\"Accuracy on test set: {:.4f}\".format(logreg.score(features_test, target_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"89421557"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","\n","pred_logreg = logreg.predict(features_test)\n","\n","confusion_matrix(target_test, pred_logreg)"]},{"cell_type":"markdown","source":["## Accuracy, Precision, Recall, F-Score"],"metadata":{"id":"eMmnvpkjHv3q"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3dbe5fae"},"outputs":[],"source":["from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","print(\"Accuracy: {:.3f}\".format(accuracy_score(target_test, pred_logreg)))\n","print(\"Precision: {:.3f}\".format(precision_score(target_test, pred_logreg)))\n","print(\"Recall: {:.3f}\".format(recall_score(target_test, pred_logreg)))\n","print(\"F-Score: {:.3f}\".format(f1_score(target_test, pred_logreg)))"]},{"cell_type":"markdown","source":["### Manually Influencing Precision and Recall"],"metadata":{"id":"7lsOM8QkH4Y0"}},{"cell_type":"code","source":["logreg.predict(features_test)"],"metadata":{"id":"igI1EHH-KwIe"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"a67de5ca"},"outputs":[],"source":["[format(x, '.3f') for x in logreg.predict_proba(features_test)[:,1]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"27ac884d"},"outputs":[],"source":["pred_logreg_thresh = logreg.predict_proba(features_test)[:,1] > 0.25\n","\n","confusion_matrix(target_test, pred_logreg_thresh)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"12f2070f"},"outputs":[],"source":["print(\"Accuracy: {:.3f}\".format(accuracy_score(target_test, pred_logreg_thresh)))\n","print(\"Precision: {:.3f}\".format(precision_score(target_test, pred_logreg_thresh)))\n","print(\"Recall: {:.3f}\".format(recall_score(target_test, pred_logreg_thresh)))\n","print(\"F-Score: {:.3f}\".format(f1_score(target_test, pred_logreg_thresh)))"]},{"cell_type":"markdown","source":["## Precision-Recall Curve"],"metadata":{"id":"cpz4mZETIDdQ"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"1920abe4"},"outputs":[],"source":["from sklearn.metrics import precision_recall_curve\n","\n","plt.figure(figsize=(8,6))\n","precision, recall, thresholds = precision_recall_curve(target_test, logreg.decision_function(features_test))\n","close_zero = np.argmin(np.abs(thresholds))\n","plt.plot(precision[close_zero], recall[close_zero], 'o', markersize=10, label=\"threshold 0.5\", fillstyle=\"none\", c='k')\n","plt.plot(precision, recall, label=\"precision recall curve\")\n","plt.xlabel(\"Precision\")\n","plt.ylabel(\"Recall\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e3fb7a6c"},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","gbc = GradientBoostingClassifier(n_estimators=1000, max_depth=3, subsample=1, learning_rate=0.1, random_state=99)\n","gbc.fit(features_train, target_train)\n","\n","print(\"Accuracy on training set: {:.3f}\".format(gbc.score(features_train, target_train)))\n","print(\"Accuracy on test set: {:.3f}\".format(gbc.score(features_test, target_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8573f180"},"outputs":[],"source":["# plot precision-recall curves of LogReg vs GBC\n","\n","plt.figure(figsize=(8,6))\n","\n","precision, recall, thresholds = precision_recall_curve(target_test, logreg.decision_function(features_test))\n","close_zero = np.argmin(np.abs(thresholds))\n","plt.xlabel(\"Precision\")\n","plt.ylabel(\"Recall\")\n","\n","precision_gbc, recall_gbc, thresholds_gbc = precision_recall_curve(\n","target_test, gbc.predict_proba(features_test)[:, 1])\n","plt.plot(precision, recall, label=\"logreg\")\n","plt.plot(precision[close_zero], recall[close_zero], 'o', markersize=10,\n","label=\"threshold 0.5 logreg\", fillstyle=\"none\", c='k')\n","plt.plot(precision_gbc, recall_gbc, label=\"gbc\")\n","close_default_gbc = np.argmin(np.abs(thresholds_gbc - 0.5))\n","plt.plot(precision_gbc[close_default_gbc], recall_gbc[close_default_gbc], '^', c='k',\n","markersize=10, label=\"threshold 0.5 gbc\", fillstyle=\"none\", mew=2)\n","plt.xlabel(\"Precision\")\n","plt.ylabel(\"Recall\")\n","plt.legend(loc=\"best\")"]},{"cell_type":"markdown","source":["## Area Under Precision-Recall Curve"],"metadata":{"id":"ZtyBIA4pIKEw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"b8dc53a6"},"outputs":[],"source":["from sklearn.metrics import average_precision_score\n","\n","auc_rf = average_precision_score(target_test, gbc.predict_proba(features_test)[:, 1])\n","auc_logreg = average_precision_score(target_test, logreg.decision_function(features_test))\n","print(\"PRC AUC of Gradient Boosting Classifier: {:.3f}\".format(ap_rf))\n","print(\"PRC AUC of Logistic Regression: {:.3f}\".format(ap_logreg))"]}]}