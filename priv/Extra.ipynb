{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "555e7886",
   "metadata": {},
   "source": [
    "# Kernelized SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1ade8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(C = 1)\n",
    "svc.fit(bc_features_train, bc_target_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(svc.score(bc_features_train, bc_target_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(svc.score(bc_features_test, bc_target_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be4ca9f",
   "metadata": {},
   "source": [
    "# Random Forest + Ridge Regression for Extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd9a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class CombinedRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, \n",
    "                 base_regressor=RandomForestRegressor, \n",
    "                 backup_regressor=Ridge, \n",
    "                 lower=0.1, \n",
    "                 upper=1.9,\n",
    "                 random_state=None,\n",
    "                 **kwargs):\n",
    "        self.base_regressor = base_regressor()\n",
    "        self.backup_regressor = backup_regressor()\n",
    "        \n",
    "        self.set_random_state(random_state)\n",
    "        \n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "        \n",
    "        self.set_params(**kwargs)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.base_regressor.fit(X, y)\n",
    "        self.backup_regressor.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        y_base = self.base_regressor.predict(X)\n",
    "        y_backup = self.backup_regressor.predict(X)\n",
    "        y_pred = np.where((self.lower * y_backup <= y_base) & (y_base <= self.upper * y_backup), \n",
    "                          y_base,\n",
    "                          y_backup)\n",
    "        return y_pred\n",
    "    \n",
    "    def __repr__(self):\n",
    "        # not as good as sklearn pretty printing,\n",
    "        # but shows updated params of subestimator\n",
    "        return f'CombinedRegressor({self.get_params()})'\n",
    "    \n",
    "    def get_params(self, deep=False, **kwargs):\n",
    "        base_regressor_params = self.base_regressor.get_params(**kwargs)\n",
    "        # remove random state as it should be a global param of the estimator\n",
    "        base_regressor_params.pop('random_state', None)\n",
    "        base_regressor_params = {'base_regressor__' + key: value \n",
    "                                 for key, value \n",
    "                                 in base_regressor_params.items()}\n",
    "        \n",
    "        backup_regressor_params = self.backup_regressor.get_params(**kwargs)\n",
    "        backup_regressor_params.pop('random_state', None)\n",
    "        backup_regressor_params = {'backup_regressor__' + key: value \n",
    "                                   for key, value \n",
    "                                   in backup_regressor_params.items()}\n",
    "        \n",
    "        own_params = {\n",
    "            'lower': self.lower,\n",
    "            'upper': self.upper,\n",
    "            'random_state': self.random_state\n",
    "        }\n",
    "        \n",
    "        params = {**own_params,\n",
    "                  **base_regressor_params, \n",
    "                  **backup_regressor_params, \n",
    "                 }\n",
    "        \n",
    "        if deep:\n",
    "            params['base_regressor'] = self.base_regressor\n",
    "            params['backup_regressor'] = self.backup_regressor\n",
    "        return params\n",
    "    \n",
    "    def set_random_state(self, value):\n",
    "        self.random_state=value\n",
    "        if 'random_state' in self.base_regressor.get_params().keys():\n",
    "            self.base_regressor.set_params(random_state=value)\n",
    "        # linear reg does not have random state, but just in case..\n",
    "        if 'random_state' in self.backup_regressor.get_params().keys():\n",
    "            self.backup_regressor.set_params(random_state=value)\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            if key.startswith('base_regressor__'):\n",
    "                trunc_key = {key[len('base_regressor__'):]: value}\n",
    "                self.base_regressor.set_params(**trunc_key)\n",
    "            elif key.startswith('backup_regressor__'):\n",
    "                trunc_key = {key[len('backup_regressor__'):]: value}\n",
    "                self.backup_regressor.set_params(**trunc_key)\n",
    "            elif key == 'random_state':\n",
    "                self.set_random_state(value)\n",
    "            else:\n",
    "                # try to fetch old value first to raise AttributeError\n",
    "                # if not exists\n",
    "                old_value = getattr(self, key)\n",
    "                setattr(self, key, value)\n",
    "        # set_params needs to return self to make gridsearch work\n",
    "        return self\n",
    "        \n",
    "    def _more_tags(self):\n",
    "        # no_validation added because validation is happening \n",
    "        # within built-in sklearn estimators\n",
    "        return {**self.base_regressor._more_tags(), 'no_validation': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b82e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = CombinedRegressor(base_regressor__n_estimators=500, base_regressor__max_depth = 5, random_state=99)\n",
    "rf.fit(ins_features_train, ins_target_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(rf.score(ins_features_train, ins_target_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(rf.score(ins_features_test, ins_target_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
