{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW_mnist.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPq97LWrMAqZCpav4jq7Xq+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"8c344b97","executionInfo":{"status":"ok","timestamp":1654798466504,"user_tz":-120,"elapsed":1379,"user":{"displayName":"Lennard Vaarten","userId":"07812007350066769398"}}},"outputs":[],"source":["# importing libraries, etc...\n","\n","import pandas as pd\n","import seaborn as sns\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","sns.set()\n","\n","path = \"https://raw.githubusercontent.com/LennardVaarten/ML-Workshops/main/data/\""]},{"cell_type":"markdown","metadata":{"id":"62c340ff"},"source":["The mnist dataset contains 70,000 labeled handwritten digits. The digits were recorded as 28x28 images, and the dataset contains the grey values of all the pixel values (so 28*28=784 pixel values for each sample). The aim is to create a model that can accurately classify whether a given digit is a 0, 1, 2, etc... \n","\n","Examples:"]},{"cell_type":"markdown","metadata":{"id":"2dd9b707"},"source":["<div>\n","<img src=\"https://raw.githubusercontent.com/LennardVaarten/ML-Workshops/main/media/mnist.png\" width=\"500\"/>\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"3cc60eff"},"source":["To make model-building a little more feasible, I've taken a subset of the dataset containing 20,000 samples, rather than the full 70,000. "]},{"cell_type":"code","execution_count":2,"metadata":{"scrolled":true,"id":"a0e778a8","executionInfo":{"status":"ok","timestamp":1654798475106,"user_tz":-120,"elapsed":3323,"user":{"displayName":"Lennard Vaarten","userId":"07812007350066769398"}}},"outputs":[],"source":["# loading\n","\n","mnist = pd.read_csv(path+\"mnist.csv\")"]},{"cell_type":"code","source":["# viewing\n","\n","mnist"],"metadata":{"id":"xA1FuWFLM_8n","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1654798475113,"user_tz":-120,"elapsed":26,"user":{"displayName":"Lennard Vaarten","userId":"07812007350066769398"}},"outputId":"ad63b3d3-c13d-427b-a2b4-4f941bb33147"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n","0          5    0    0    0    0    0    0    0    0    0  ...      0      0   \n","1          0    0    0    0    0    0    0    0    0    0  ...      0      0   \n","2          4    0    0    0    0    0    0    0    0    0  ...      0      0   \n","3          1    0    0    0    0    0    0    0    0    0  ...      0      0   \n","4          9    0    0    0    0    0    0    0    0    0  ...      0      0   \n","...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n","19995      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n","19996      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n","19997      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n","19998      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n","19999      2    0    0    0    0    0    0    0    0    0  ...      0      0   \n","\n","       28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n","0          0      0      0      0      0      0      0      0  \n","1          0      0      0      0      0      0      0      0  \n","2          0      0      0      0      0      0      0      0  \n","3          0      0      0      0      0      0      0      0  \n","4          0      0      0      0      0      0      0      0  \n","...      ...    ...    ...    ...    ...    ...    ...    ...  \n","19995      0      0      0      0      0      0      0      0  \n","19996      0      0      0      0      0      0      0      0  \n","19997      0      0      0      0      0      0      0      0  \n","19998      0      0      0      0      0      0      0      0  \n","19999      0      0      0      0      0      0      0      0  \n","\n","[20000 rows x 785 columns]"],"text/html":["\n","  <div id=\"df-0d26142b-82e1-47cb-bea2-7af53c1b902f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>1x1</th>\n","      <th>1x2</th>\n","      <th>1x3</th>\n","      <th>1x4</th>\n","      <th>1x5</th>\n","      <th>1x6</th>\n","      <th>1x7</th>\n","      <th>1x8</th>\n","      <th>1x9</th>\n","      <th>...</th>\n","      <th>28x19</th>\n","      <th>28x20</th>\n","      <th>28x21</th>\n","      <th>28x22</th>\n","      <th>28x23</th>\n","      <th>28x24</th>\n","      <th>28x25</th>\n","      <th>28x26</th>\n","      <th>28x27</th>\n","      <th>28x28</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>19995</th>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19996</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19997</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19998</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19999</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>20000 rows Ã— 785 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d26142b-82e1-47cb-bea2-7af53c1b902f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0d26142b-82e1-47cb-bea2-7af53c1b902f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0d26142b-82e1-47cb-bea2-7af53c1b902f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"8aca365d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654798475118,"user_tz":-120,"elapsed":21,"user":{"displayName":"Lennard Vaarten","userId":"07812007350066769398"}},"outputId":"ec36417a-82ca-4260-f7a3-26db89ab621d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":4}],"source":["# Check if there are any missing values...\n","\n","mnist.isna().any(axis=1).sum()\n","\n","# Nope!"]},{"cell_type":"markdown","metadata":{"id":"bee757b2"},"source":["Splitting into training and test set. \n","\n","(Changing the random_state parameter in the train_test_split function to a different number will result in a different random split of the data. Try playing around with it and then running your model(s) again to see how a different split might result in a different score.)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"45b22ecf","executionInfo":{"status":"ok","timestamp":1654798477038,"user_tz":-120,"elapsed":820,"user":{"displayName":"Lennard Vaarten","userId":"07812007350066769398"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","features_train, features_test, target_train, target_test = train_test_split(mnist.iloc[:,1:], \n","                                                                    mnist.iloc[:,0], \n","                                                                    random_state=99)"]},{"cell_type":"markdown","metadata":{"id":"fef1fbbd"},"source":["Let's start with our good old k-NN classifier...\n","\n","Note that even this subset I've taken of the mnist dataset is quite large, with 20,000 samples and 784 features. Because of this, model-building / prediction can take some time.\n","\n","However, we can save a bit of time by using the n_jobs parameter when building a model. Setting n_jobs=-1 (as done below) tells sklearn to use all of your CPU cores, whereas by default it will only use 1. This means that if your PC has 8 CPU cores, building the model will be 8 times as fast!"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"87cbbcad","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654798518151,"user_tz":-120,"elapsed":38355,"user":{"displayName":"Lennard Vaarten","userId":"07812007350066769398"}},"outputId":"b8d916e7-1434-4fd3-9d5a-b8ce46f32e00"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training set score: 0.9611\n","Test set score: 0.9530\n"]}],"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","knn = KNeighborsClassifier(n_neighbors=9, weights=\"uniform\", n_jobs=-1).fit(features_train, target_train)\n","print(\"Training set score: {:.4f}\".format(knn.score(features_train, target_train)))\n","print(\"Test set score: {:.4f}\".format(knn.score(features_test, target_test)))"]},{"cell_type":"markdown","metadata":{"id":"793286b2"},"source":["Now, it's your turn to use any of the models we've discussed to see how well they perform on this task. Note that this is a classification problem, so only classification models will work on it. Perhaps even more important than choosing a classifier is trying out different parameter settings (e.g. n_neighbors for k-Nearest Neighbors, C for Logistic Regression, n_estimators for the Random Forest Classifier, etc...). \n","\n","Below are the classification models we've discussed, along with the import statement and the parameters that we've covered during the sessions.\n","\n","- **k-Nearest Neighbors Classifier** (already imported in the cell above)\n","    - n_neighbors (any number above 0)\n","    - weights (\"uniform\", \"distance\")\n","- **Decision Tree Classifier** (from sklearn.tree import DecisionTreeClassifier)\n","    - max_depth (a whole number above 0)\n","    - min_samples_split (a whole number above 1)\n","- **Random Forest Classifier** (from sklearn.ensemble import RandomForestClassifier)\n","    - n_estimators (a whole number above 0)\n","    - max_depth (a whole number above 0)\n","    - min_samples_split (a whole number above 1)\n","- **Gradient Boosting Classifier** (from sklearn.ensemble import GradientBoostingClassifier)\n","    - n_estimators (a whole number above 0)\n","    - max_depth (a whole number above 0)\n","    - min_samples_split (a whole number above 1)\n","    - learning_rate (a number between 0 and 1)\n","    - subsample (a number between 0 and 1)\n","    \n","If you want to access even more parameter settings than we've discussed in class (models tend to have a lot), you can also access the sklearn documentation. For example, [here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html), you can find all possible parameters to tune for the KNeighborsClassifier.\n","\n","Good luck and feel free to share your model (and the results you obtain with it) on the Canvas discussion page!"]},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_score\n","from sklearn.ensemble import RandomForestClassifier\n","\n","rf = RandomForestClassifier(n_estimators=500, random_state=99)\n","rf.fit(features_train, target_train)\n","\n","rfScores = cross_val_score(rf, features_train, target_train, cv=10)\n","print(rfScores)\n","print(f\"Random Forest mean 5-fold Cross-Validation score: {np.mean(rfScores):.3f}\")"],"metadata":{"id":"yC3lqvQFuGGw"},"execution_count":null,"outputs":[]}]}